{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "F2EfDfJQJVNa"
      },
      "outputs": [],
      "source": [
        "#____importing Libraries_____#\n",
        "import sklearn.neighbors\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn import model_selection\n",
        "from sklearn.feature_extraction.text import CountVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hhBkPkdpJVNb",
        "outputId": "02fcf949-a3bf-4240-b63c-e68ef0d8b057"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(18846, 173762)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#____Setting up HyperParameters____#\n",
        "cats = ['rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.space', 'rec.motorcycles', 'misc.forsale']\n",
        "newsgroups = fetch_20newsgroups(subset='all')\n",
        "vectorizer = TfidfVectorizer()\n",
        "# corpus = ['This is the first document.','This document is the second document.','And this is the third one.','Is this the first document?']\n",
        "# vectorizer = TfidfVectorizer()\n",
        "# X = vectorizer.fit_transform(corpus)\n",
        "# print(vectorizer.get_feature_names())\n",
        "\n",
        "\n",
        "#___ Preprocessing on data using Tf-Idf_____#\n",
        "X = vectorizer.fit_transform(newsgroups.data)\n",
        "y = newsgroups.target\n",
        "# print(vectorizer.get_feature_names())\n",
        "print(X.shape)\n",
        "# print(y)\n",
        "weights = 'uniform' # Using Unifor Disturbuted for weight initialization\n",
        "\n",
        "#___ defining the classifier(KNN)____#\n",
        "clf = sklearn.neighbors.KNeighborsClassifier(n_neighbors=1, weights=weights)\n",
        "\n",
        "#___ K-Fold (5-Fold) ___#\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fsi8xJDZJVNc",
        "outputId": "1771c906-b56e-4262-f277-25ff27071abe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test size is: 20%\n",
            "accuracy before cross-validation is 0.84\n",
            "Accuracy: 0.83 (+/- 0.01)\n",
            "Classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.87      0.84       167\n",
            "           1       0.80      0.70      0.75       195\n",
            "           2       0.74      0.76      0.75       180\n",
            "           3       0.77      0.70      0.73       204\n",
            "           4       0.76      0.82      0.79       195\n",
            "           5       0.89      0.80      0.85       204\n",
            "           6       0.76      0.65      0.70       211\n",
            "           7       0.88      0.83      0.85       204\n",
            "           8       0.93      0.92      0.93       202\n",
            "           9       0.88      0.93      0.90       190\n",
            "          10       0.91      0.93      0.92       206\n",
            "          11       0.91      0.91      0.91       211\n",
            "          12       0.77      0.82      0.80       165\n",
            "          13       0.90      0.89      0.89       212\n",
            "          14       0.88      0.88      0.88       184\n",
            "          15       0.90      0.86      0.88       185\n",
            "          16       0.84      0.88      0.86       185\n",
            "          17       0.86      0.95      0.91       199\n",
            "          18       0.83      0.89      0.86       154\n",
            "          19       0.74      0.86      0.80       117\n",
            "\n",
            "    accuracy                           0.84      3770\n",
            "   macro avg       0.84      0.84      0.84      3770\n",
            "weighted avg       0.84      0.84      0.84      3770\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def cross_validation(data, target, classifier, cv=5):\n",
        "    return sklearn.model_selection.cross_val_score(classifier, data, target, cv=cv)\n",
        "\n",
        "def test_classifier(X, y, clf, test_size=0.4, y_names=None):\n",
        "    # train-test split\n",
        "    print('test size is: %2.0f%%' % (test_size * 100))\n",
        "    X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y, test_size=test_size)\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_predicted = clf.predict(X_test)\n",
        "    print (\"accuracy before cross-validation is %0.2f\" % accuracy_score(y_test, y_predicted))\n",
        "    scores = cross_validation(X, y, clf, cv=5)\n",
        "    print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
        "    print('Classification report:')\n",
        "    print(sklearn.metrics.classification_report(y_test, y_predicted, target_names=y_names))\n",
        "test_classifier(X,y, clf, test_size=0.2, y_names=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "jVWBVi_ZJVNd"
      },
      "outputs": [],
      "source": [
        "#_______Import libraries_______#\n",
        "import numpy as np\n",
        "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import pairwise_distances\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.utils.multiclass import check_classification_targets\n",
        "# from sklearn.datasets import fetch_20newsgroups\n",
        "\n",
        "#______Define hyper parameters______#\n",
        "cats = ['rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.space', 'rec.motorcycles', 'misc.forsale']\n",
        "metric = 'euclidean'\n",
        "#_____Load data_____#\n",
        "newsgroups = fetch_20newsgroups(subset='train', categories=cats, remove=('headers', 'footers', 'quotes'))\n",
        "#_____Preprocessing_____#\n",
        "vectorizer = TfidfVectorizer()\n",
        "X = vectorizer.fit_transform(newsgroups.data) # Convert to Tf-Idf vectorization\n",
        "y = newsgroups.target\n",
        "\n",
        "\n",
        "\n",
        "check_classification_targets(y) # Ensure that target y is of a non-regression type.\n",
        "\n",
        "\n",
        "n_samples, n_features = X.shape\n",
        "#_____Defining classes(centroids)______#\n",
        "le = LabelEncoder()\n",
        "y_indices = le.fit_transform(y)\n",
        "classes = le.classes_\n",
        "n_classes = classes.size\n",
        "\n",
        "# Mask mapping each class to its members.\n",
        "centroids = np.empty((n_classes, n_features), dtype=np.float64)\n",
        "# Number of clusters in each class.\n",
        "n_cluster = np.zeros(n_classes)\n",
        "\n",
        "for current_class in range(n_classes):\n",
        "    center_mask = y_indices == current_class\n",
        "    n_cluster[current_class] = np.sum(center_mask)\n",
        "    centroids[current_class] = X[center_mask].mean(axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ga1pPabZJVNe",
        "outputId": "6b730ff7-3612-4595-ce63-8e73d225a8d0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0.7080168776371308'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "def get_vectorizer_array(query):\n",
        "    return vectorizer.transform([query]).toarray()\n",
        "\n",
        "\n",
        "def pred(X):\n",
        "    return classes[pairwise_distances(X, centroids, metric=metric).argmin(axis=1)]\n",
        "\n",
        "\n",
        "\t\n",
        "#____Get test Data_____#\n",
        "newsgroups_test = fetch_20newsgroups(subset='test', categories=cats, remove=('headers', 'footers', 'quotes'))\n",
        "x_testdata = newsgroups_test.data\n",
        "y_test = newsgroups_test.target\n",
        "testdata = [[a_, b_] for a_, b_ in zip(x_testdata, y_test)]\n",
        "\n",
        "correct = sum(str(pred(get_vectorizer_array(testcase[0]))[0]) == str(testcase[1]) for testcase in testdata)\n",
        "\n",
        "\n",
        "# Print the accurency in percentage\n",
        "result = str(correct / len(testdata))\n",
        "result"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}